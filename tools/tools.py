"""
APQR System Tools
Functional tools for LIMS, ERP, and DMS operations with APQR_Segregated integration.
These tools are called by ADK agents to retrieve pharmaceutical data.

Tools Architecture:
- LIMS Tools: Access APQR_Segregated/LIMS/ (COA, QC records, batch documentation)
- ERP Tools: Access APQR_Segregated/ERP/ (Manufacturing, SupplyChain, Engineering records)
- DMS Tools: Access APQR_Segregated/DMS/ (SOPs, Training records, CAPA documents)
"""

import logging
import os
import json
from pathlib import Path
from typing import Dict, Any, List

logger = logging.getLogger(__name__)

# Import parsing tools
from .pdf_tools import parse_coa_pdf, parse_sds_pdf, extract_text_from_pdf
from .word_tools import parse_bmr_docx, parse_sop_docx, extract_text_from_docx
from .excel_tools import parse_batch_data_xlsx, parse_kpi_data_xlsx, extract_data_from_xlsx

# Get the base path for APQR_Segregated
BASE_DIR = Path(__file__).resolve().parent.parent  # Go up to agentic_apqr folder
APQR_DATA_DIR = BASE_DIR / "APQR_Segregated"
LIMS_DOCS_DIR = APQR_DATA_DIR / "LIMS"
ERP_DOCS_DIR = APQR_DATA_DIR / "ERP"
DMS_DOCS_DIR = APQR_DATA_DIR / "DMS"
METADATA_DIR = BASE_DIR / "database_metadata"


def read_database_index(domain: str) -> str:
    """
    Read the database metadata index for a specific domain.
    
    Args:
        domain: One of 'ERP', 'LIMS', 'DMS'
        
    Returns:
        Content of the index file as string, or empty string if not found
    """
    try:
        index_file = METADATA_DIR / f"{domain}_INDEX.txt"
        if index_file.exists():
            with open(index_file, 'r', encoding='utf-8') as f:
                return f.read()
        else:
            logger.warning(f"Database index not found: {index_file}")
            return ""
    except Exception as e:
        logger.error(f"Error reading database index for {domain}: {e}")
        return ""


def list_available_documents(directory: Path) -> List[Path]:
    """
    List all documents available in a directory (recursively searches all subdirectories).
    
    Args:
        directory: Path to the directory
        
    Returns:
        List of full Path objects for all files found recursively
    """
    try:
        if directory.exists():
            # Recursively search for all files in subdirectories
            all_files = []
            for file_path in directory.rglob('*'):
                if file_path.is_file():
                    all_files.append(file_path)  # Return full Path object
            return all_files
        return []
    except Exception as e:
        logger.error(f"Error listing documents in {directory}: {e}")
        return []


def get_document_info(doc_path: Path) -> Dict[str, Any]:
    """
    Get information about a document.
    
    Args:
        doc_path: Path to the document
        
    Returns:
        Dictionary with document metadata
    """
    try:
        if doc_path.exists():
            stat = doc_path.stat()
            return {
                "filename": doc_path.name,
                "path": str(doc_path),
                "size_bytes": stat.st_size,
                "size_kb": round(stat.st_size / 1024, 2),
                "exists": True
            }
        return {"filename": doc_path.name, "exists": False}
    except Exception as e:
        logger.error(f"Error getting document info for {doc_path}: {e}")
        return {"error": str(e)}


# =======================
# LIMS Tools
# =======================

def query_lims_qc(query: str) -> str:
    """
    Query Quality Control data from LIMS.
    
    **ğŸ” USES DATABASE INDEX: database_metadata/LIMS_INDEX.txt**
    This index contains file locations, naming patterns, and batch mapping for all LIMS documents.
    
    **Tool: COA Analyzer, QC Register Extractor, OOS Trend Evaluator**
    
    Args:
        query: User query about QC, COA, assay results, OOS, etc.
        
    Returns:
        JSON string with parsed COA data from APQR_Segregated/LIMS/
    """
    logger.info(f"ğŸ”¬ LIMS QC Tool called with query: {query}")
    
    try:
        # ğŸ” NEW: Read the LIMS database index for intelligent file search
        lims_index = read_database_index("LIMS")
        if lims_index:
            logger.info("âœ… LIMS database index loaded for intelligent file search")
        
        # List available COA documents (recursively searches all subdirectories)
        available_docs = list_available_documents(LIMS_DOCS_DIR)
        coa_docs = [doc for doc in available_docs if 'COA' in doc.name.upper()]
        
        if not coa_docs:
            return json.dumps({
                "status": "no_information_found",
                "message": "No COA documents found in LIMS directory",
                "query": query,
                "data_source": "APQR_Segregated/LIMS/",
                "search_note": "Searched for COA documents across all batches (both PDF and DOCX formats)"
            })
        
        logger.info(f"ğŸ”¬ Found {len(coa_docs)} COA documents")
        
        # Parse all available COA documents (handles both PDF and DOCX)
        parsed_coas = []
        for doc_path in coa_docs:
            if doc_path.exists():
                logger.info(f"Parsing COA: {doc_path.name} from {doc_path.parent}")
                # Parse PDF documents (Batch 1)
                if doc_path.name.endswith('.pdf'):
                    coa_data = parse_coa_pdf(str(doc_path))
                    coa_data['batch'] = "ASP-25-001"  # Batch 1 uses PDF
                    parsed_coas.append(coa_data)
                # Parse DOCX documents (Batch 2-4)
                elif doc_path.name.endswith('.docx'):
                    text = extract_text_from_docx(str(doc_path))
                    # Extract batch number from filename
                    batch = "ASP-25-002" if "002" in doc_path.name else "ASP-25-003" if "003" in doc_path.name else "ASP-25-004" if "004" in doc_path.name else "Unknown"
                    coa_data = {
                        "filename": doc_path.name,
                        "batch": batch,
                        "material": "API" if "API" in doc_path.name else "Binder" if "Binder" in doc_path.name else "Diluent" if "Diluent" in doc_path.name else "Disintegrant" if "Disintegrant" in doc_path.name else "Lubricant" if "Lubricant" in doc_path.name else "Unknown",
                        "raw_text": text,
                        "source": str(doc_path)
                    }
                    parsed_coas.append(coa_data)
        
        # Return structured JSON data
        result = {
            "status": "success",
            "query": query,
            "data_source": "APQR_Segregated/LIMS/",
            "document_count": len(parsed_coas),
            "documents": parsed_coas
        }
        
        return json.dumps(result, indent=2)
        
    except Exception as e:
        logger.error(f"Error in query_lims_qc: {e}")
        return json.dumps({
            "status": "error",
            "message": str(e),
            "query": query
        })


def query_lims_validation(query: str) -> str:
    """
    Query Validation data from LIMS.
    
    **ğŸ” USES DATABASE INDEX: database_metadata/LIMS_INDEX.txt**
    This index contains file locations, naming patterns, and batch mapping for all LIMS documents.
    
    **Tool: Protocol Mapper, Qualification Report Parser, Trend Tracker**
    
    Args:
        query: User query about validation, qualification, protocols, etc.
        
    Returns:
        Formatted string with validation data from APQR_Segregated/LIMS/
    """
    logger.info(f"ğŸ“‹ LIMS Validation Tool called with query: {query}")
    
    # ğŸ” NEW: Read the LIMS database index for intelligent file search
    lims_index = read_database_index("LIMS")
    if lims_index:
        logger.info("âœ… LIMS database index loaded for intelligent file search")
    
    # List available LIMS documents
    available_docs = list_available_documents(LIMS_DOCS_DIR)
    
    result = f"""**ğŸ“‹ Validation Data (LIMS)**

**Query:** {query}

**Available LIMS Documents:** {len(available_docs)} files
"""
    
    for doc_path in available_docs[:5]:  # Show first 5
        info = get_document_info(doc_path)
        if info.get('exists'):
            result += f"\nğŸ“„ {info['filename']} ({info['size_kb']} KB)"
    
    result += f"""

**Data Source:** LIMS APQR_Segregated/LIMS/

**Validation Capabilities:**
- âœ… Protocol Mapping: Map and track validation protocols
- âœ… Qualification Report Parser: Extract IQ/OQ/PQ data
- âœ… Trend Tracker: Monitor validation trends
- âœ… Equipment qualification status tracking

**Available Data Types:**
- Validation protocols
- IQ/OQ/PQ reports
- Equipment qualification records
- Method validation summaries

**Documents Available:** {', '.join(available_docs)}
"""
    
    return result


def query_lims_rnd(query: str) -> str:
    """
    Query R&D data from LIMS.
    
    **ğŸ” USES DATABASE INDEX: database_metadata/LIMS_INDEX.txt**
    This index contains file locations, naming patterns, and batch mapping for all LIMS documents.
    
    **Tool: Experimental Data Summarizer, Stability Data Comparator, Product Development Log Analyzer**
    
    Args:
        query: User query about R&D, stability, formulation, etc.
        
    Returns:
        Formatted string with R&D data from APQR_Segregated/LIMS/
    """
    logger.info(f"ğŸ§ª LIMS R&D Tool called with query: {query}")
    
    # ğŸ” NEW: Read the LIMS database index for intelligent file search
    lims_index = read_database_index("LIMS")
    if lims_index:
        logger.info("âœ… LIMS database index loaded for intelligent file search")
    
    # List available LIMS documents
    available_docs = list_available_documents(LIMS_DOCS_DIR)
    
    result = f"""**ğŸ§ª R&D Data (LIMS)**

**Query:** {query}

**Available R&D Documents:** {len(available_docs)} files from LIMS

**Data Source:** LIMS APQR_Segregated/LIMS/

**R&D Capabilities:**
- âœ… Experimental Data Summarizer: Aggregate and summarize R&D experiments
- âœ… Stability Data Comparator: Compare stability studies across batches
- âœ… Product Development Log Analyzer: Track product development history
- âœ… Critical Quality Attributes (CQA) tracking

**Available Data Types:**
- Stability studies and trending
- Formulation development data
- Experimental results
- Product development logs
- CQA tracking and analysis

**Documents:** {', '.join(available_docs)}

**R&D Focus Areas:**
- Stability testing and trending
- Formulation optimization
- Experimental protocols
- Development milestones
"""
    
    return result


# =======================
# ERP Tools
# =======================

def query_erp_manufacturing(query: str) -> str:
    """
    Query Manufacturing data from ERP.
    
    **ğŸ” USES DATABASE INDEX: database_metadata/ERP_INDEX.txt**
    This index contains file locations, naming patterns, and batch mapping for all ERP documents.
    
    **Tool: Batch Manufacturing Record Analyzer, Yield Reconciliation Tool, Deviation Log Interpreter**
    
    Args:
        query: User query about batch records, BMR, yield, etc.
        
    Returns:
        Formatted string with manufacturing data from APQR_Segregated/ERP/
    """
    logger.info(f"ğŸ­ ERP Manufacturing Tool called with query: {query}")
    
    # ğŸ” NEW: Read the ERP database index for intelligent file search
    erp_index = read_database_index("ERP")
    if erp_index:
        logger.info("âœ… ERP database index loaded for intelligent file search")
    
    # List available ERP documents
    available_docs = list_available_documents(ERP_DOCS_DIR)
    
    # Get document information
    doc_details = []
    for doc_path in available_docs:
        info = get_document_info(doc_path)
        doc_details.append(info)
    
    result = f"""**ğŸ­ Manufacturing Data (ERP)**

**Query:** {query}

**Available Manufacturing Documents:**
"""
    
    for info in doc_details:
        if info.get('exists'):
            result += f"\nğŸ“„ **{info['filename']}**"
            result += f"\n   - Size: {info['size_kb']} KB"
            result += f"\n   - Path: {info['path']}"
            result += "\n"
    
    result += f"""
**Data Source:** ERP APQR_Segregated/ERP/
**Total Documents:** {len(available_docs)}

**Manufacturing Capabilities:**
- âœ… Batch Manufacturing Record (BMR) Analyzer
- âœ… Yield Reconciliation Tool: Calculate and verify yields
- âœ… Deviation Log Interpreter: Analyze manufacturing deviations
- âœ… Production tracking and batch traceability

**Available Data Types:**
- Batch Manufacturing Records (BMR)
- Batch Production Records (BPR)
- Purchase Orders and Requisition Slips
- Yield reconciliation data
- Manufacturing deviation logs

**Documents:** {', '.join(available_docs)}
"""
    
    return result


def query_erp_engineering(query: str) -> str:
    """
    Query Engineering data from ERP.
    
    **ğŸ” USES DATABASE INDEX: database_metadata/ERP_INDEX.txt**
    This index contains file locations, naming patterns, and batch mapping for all ERP documents.
    
    **Tool: Equipment Calibration Extractor, Maintenance Log Reader, Utility Performance Tracker**
    
    Args:
        query: User query about equipment, calibration, maintenance, etc.
        
    Returns:
        Formatted string with engineering data from APQR_Segregated/ERP/
    """
    logger.info(f"âš™ï¸ ERP Engineering Tool called with query: {query}")
    
    # ğŸ” NEW: Read the ERP database index for intelligent file search
    erp_index = read_database_index("ERP")
    if erp_index:
        logger.info("âœ… ERP database index loaded for intelligent file search")
    
    # List available ERP documents
    available_docs = list_available_documents(ERP_DOCS_DIR)
    
    result = f"""**âš™ï¸ Engineering Data (ERP)**

**Query:** {query}

**Available Engineering Documents:** {len(available_docs)} files

**Data Source:** ERP APQR_Segregated/ERP/

**Engineering Capabilities:**
- âœ… Equipment Calibration Extractor: Extract calibration records
- âœ… Maintenance Log Reader: Read and analyze maintenance histories
- âœ… Utility Performance Tracker: Monitor utility systems (HVAC, Water, etc.)
- âœ… Equipment qualification status tracking

**Available Data Types:**
- Equipment calibration records
- Preventive & corrective maintenance logs
- Utility performance data
- Equipment qualification status
- Engineering change control

**Documents:** {', '.join(available_docs)}

**Engineering Focus Areas:**
- Calibration management
- Maintenance scheduling
- Utility monitoring
- Equipment lifecycle tracking
"""
    
    return result


def query_erp_supplychain(query: str) -> str:
    """
    Query Supply Chain data from ERP.
    
    **ğŸ” USES DATABASE INDEX: database_metadata/ERP_INDEX.txt**
    This index contains file locations, naming patterns, and batch mapping for all ERP documents.
    
    **Tool: Vendor Qualification Extractor, Purchase Order & GRN Tracker, Material Reconciliation Analyzer**
    
    Args:
        query: User query about GRN, PO, vendors, materials, etc.
        
    Returns:
        JSON string with parsed PO/Requisition data from APQR_Segregated/ERP/
    """
    logger.info(f"ğŸ“¦ ERP Supply Chain Tool called with query: {query}")
    
    try:
        # ğŸ” NEW: Read the ERP database index for intelligent file search
        erp_index = read_database_index("ERP")
        if erp_index:
            logger.info("âœ… ERP database index loaded for intelligent file search")
        
        # List available ERP documents (recursively searches all subdirectories)
        available_docs = list_available_documents(ERP_DOCS_DIR)
        
        # ğŸ” ENHANCED: Search for supply chain documents using multiple patterns
        # Pattern 1: "Purchase Order" or "Requisition" (Batch 1 style)
        # Pattern 2: Material names followed by ASP-25 (Batch 2-4 style: "Binder - ASP-25-002.docx")
        # Pattern 3: "PO" in filename
        
        # Extract material keywords from query
        material_keywords = ['API', 'Binder', 'Diluent', 'Disintegrant', 'Lubricant', 
                            'HPMC', 'MCC', 'Cornstarch', 'Magnesium', 'Salicylic']
        
        supply_chain_docs = []
        for doc in available_docs:
            # Check if it's in SupplyChain folder
            if 'SupplyChain' in str(doc):
                # Pattern matching for supply chain documents
                if any([
                    'Purchase Order' in doc.name,
                    'Requisition' in doc.name,
                    'PO-' in doc.name,
                    'Req. Slip' in doc.name,
                    # Match material names for Batch 2-4 style files
                    any(material in doc.name for material in material_keywords) and 'ASP-25' in doc.name,
                    # Match direct material name files (like "Binder - ASP-25-002.docx")
                    any(material in doc.name for material in material_keywords) and 'ASP' in doc.name
                ]):
                    supply_chain_docs.append(doc)
        
        if not supply_chain_docs:
            return json.dumps({
                "status": "no_information_found",
                "message": "No Purchase Order or Requisition documents found in ERP directory",
                "query": query,
                "data_source": "APQR_Segregated/ERP/",
                "search_note": "Searched for: Purchase Orders, Requisition Slips, and material-specific procurement documents across all batches"
            })
        
        logger.info(f"ğŸ“¦ Found {len(supply_chain_docs)} supply chain documents")
        
        # Parse all available supply chain documents
        parsed_docs = []
        for doc_path in supply_chain_docs:
            if doc_path.exists():
                logger.info(f"Parsing Supply Chain document: {doc_path.name} from {doc_path.parent}")
                # Parse PDF documents
                if doc_path.name.endswith('.pdf'):
                    text = extract_text_from_pdf(str(doc_path))
                    parsed_docs.append({
                        "filename": doc_path.name,
                        "document_type": "Purchase Order" if "Purchase Order" in doc_path.name else "Procurement Document",
                        "batch": "ASP-25-002" if "002" in doc_path.name else "ASP-25-003" if "003" in doc_path.name else "ASP-25-004" if "004" in doc_path.name else "ASP-25-001",
                        "raw_text": text,
                        "source": str(doc_path)
                    })
                # Parse DOCX documents (Batch 2-4 use DOCX)
                elif doc_path.name.endswith('.docx'):
                    text = extract_text_from_docx(str(doc_path))
                    parsed_docs.append({
                        "filename": doc_path.name,
                        "document_type": "Purchase Order" if "Purchase Order" in doc_path.name or "PO" in doc_path.name else "Procurement Document",
                        "batch": "ASP-25-002" if "002" in doc_path.name else "ASP-25-003" if "003" in doc_path.name else "ASP-25-004" if "004" in doc_path.name else "ASP-25-001",
                        "raw_text": text,
                        "source": str(doc_path)
                    })
        
        # Return structured JSON data
        result = {
            "status": "success",
            "query": query,
            "data_source": "APQR_Segregated/ERP/",
            "document_count": len(parsed_docs),
            "batches_found": list(set([doc.get("batch") for doc in parsed_docs])),
            "documents": parsed_docs
        }
        
        return json.dumps(result, indent=2)
        
    except Exception as e:
        logger.error(f"Error in query_erp_supplychain: {e}")
        return json.dumps({
            "status": "error",
            "message": str(e),
            "query": query
        })


# =======================
# DMS Tools
# =======================

def query_dms_qa(query: str) -> str:
    """
    Query Quality Assurance documents from DMS.
    
    **ğŸ” USES DATABASE INDEX: database_metadata/DMS_INDEX.txt**
    This index contains file locations, naming patterns, and document categorization for all DMS documents.
    
    **Tool: CAPA Tracker, Change Control Parser, Training Effectiveness Evaluator**
    
    Args:
        query: User query about CAPA, change control, deviations, etc.
        
    Returns:
        Formatted string with QA documents from APQR_Segregated/DMS/
    """
    logger.info(f"ğŸ“‹ DMS QA Tool called with query: {query}")
    
    # ğŸ” NEW: Read the DMS database index for intelligent file search
    dms_index = read_database_index("DMS")
    if dms_index:
        logger.info("âœ… DMS database index loaded for intelligent file search")
    
    # List available DMS documents
    available_docs = list_available_documents(DMS_DOCS_DIR)
    sds_docs = [doc for doc in available_docs if 'SDS' in doc.name.upper()]
    
    # Get document information
    doc_details = []
    for doc_path in sds_docs:
        info = get_document_info(doc_path)
        doc_details.append(info)
    
    result = f"""**ğŸ“‹ Quality Assurance Documents (DMS)**

**Query:** {query}

**Available QA Documents:**
"""
    
    for info in doc_details:
        if info.get('exists'):
            result += f"\nğŸ“„ **{info['filename']}**"
            result += f"\n   - Size: {info['size_kb']} KB"
            result += "\n"
    
    result += f"""
**Data Source:** DMS APQR_Segregated/DMS/
**Total SDS Documents:** {len(sds_docs)}

**QA Capabilities:**
- âœ… CAPA Tracker: Track CAPA status and closure
- âœ… Change Control Parser: Parse and track change controls
- âœ… Training Effectiveness Evaluator: Evaluate training outcomes
- âœ… Deviation management and trending

**Available Data Types:**
- CAPA (Corrective and Preventive Actions)
- Change control documents
- Deviation reports
- Non-conformance records
- Quality investigations
- Safety Data Sheets (SDS)

**Documents:** {', '.join(available_docs)}

**QA Focus Areas:**
- CAPA effectiveness
- Change control compliance
- Deviation trending
- Quality metrics
"""
    
    return result


def query_dms_regulatory(query: str) -> str:
    """
    Query Regulatory Affairs documents from DMS.
    
    **ğŸ” USES DATABASE INDEX: database_metadata/DMS_INDEX.txt**
    This index contains file locations, naming patterns, and document categorization for all DMS documents.
    
    **Tool: Product Dossier Compiler, Variation Tracker, Regulatory Submission Extractor**
    
    Args:
        query: User query about dossiers, submissions, regulatory commitments, SDS, etc.
        
    Returns:
        JSON string with parsed SDS/regulatory data from APQR_Segregated/DMS/
    """
    logger.info(f"âš–ï¸ DMS Regulatory Tool called with query: {query}")
    
    try:
        # ğŸ” NEW: Read the DMS database index for intelligent file search
        dms_index = read_database_index("DMS")
        if dms_index:
            logger.info("âœ… DMS database index loaded for intelligent file search")
        
        # List available DMS documents (recursively searches all subdirectories)
        available_docs = list_available_documents(DMS_DOCS_DIR)
        sds_docs = [doc for doc in available_docs if 'SDS' in doc.name.upper()]
        
        if not sds_docs:
            return json.dumps({
                "status": "no_information_found",
                "message": "No SDS or regulatory documents found in DMS directory",
                "query": query,
                "data_source": "APQR_Segregated/DMS/"
            })
        
        # Parse all available SDS documents
        parsed_sds = []
        for doc_path in sds_docs:
            if doc_path.exists():
                logger.info(f"Parsing SDS: {doc_path.name} from {doc_path.parent}")
                sds_data = parse_sds_pdf(str(doc_path))
                parsed_sds.append(sds_data)
        
        # Return structured JSON data
        result = {
            "status": "success",
            "query": query,
            "data_source": "APQR_Segregated/DMS/",
            "document_count": len(parsed_sds),
            "documents": parsed_sds
        }
        
        return json.dumps(result, indent=2)
        
    except Exception as e:
        logger.error(f"Error in query_dms_regulatory: {e}")
        return json.dumps({
            "status": "error",
            "message": str(e),
            "query": query
        })


def query_dms_management(query: str) -> str:
    """
    Query Management documents from DMS.
    
    **ğŸ” USES DATABASE INDEX: database_metadata/DMS_INDEX.txt**
    This index contains file locations, naming patterns, and document categorization for all DMS documents.
    
    **Tool: Audit Summary Analyzer, KPI Dashboard Generator, Review Meeting Log Extractor**
    
    Args:
        query: User query about audits, KPIs, approvals, etc.
        
    Returns:
        Formatted string with management documents from APQR_Segregated/DMS/
    """
    logger.info(f"ğŸ“Š DMS Management Tool called with query: {query}")
    
    # ğŸ” NEW: Read the DMS database index for intelligent file search
    dms_index = read_database_index("DMS")
    if dms_index:
        logger.info("âœ… DMS database index loaded for intelligent file search")
    
    # List available DMS documents
    available_docs = list_available_documents(DMS_DOCS_DIR)
    
    result = f"""**ğŸ“Š Management Documents & Reports (DMS)**

**Query:** {query}

**Available Management Documents:** {len(available_docs)} files

**Data Source:** DMS APQR_Segregated/DMS/

**Management Capabilities:**
- âœ… Audit Summary Analyzer: Analyze audit reports and findings
- âœ… KPI Dashboard Generator: Generate KPI dashboards and metrics
- âœ… Review Meeting Log Extractor: Extract meeting logs and action items
- âœ… APQR approval tracking

**Available Data Types:**
- Audit reports and findings
- Key Performance Indicators (KPIs)
- APQR approvals and sign-offs
- Management review records
- Executive summaries
- Quality metrics dashboards

**Documents:** {', '.join(available_docs)}

**Management Focus:**
- Audit response and CAPA
- Performance metrics
- Executive reporting
- Management reviews
- Strategic planning
"""
    
    return result


def query_dms_training(query: str) -> str:
    """
    Query HR/Training documents from DMS.
    
    **ğŸ” USES DATABASE INDEX: database_metadata/DMS_INDEX.txt**
    This index contains file locations, naming patterns, and document categorization for all DMS documents.
    
    **Tool: Training Matrix Reader, Competency Evaluation Extractor, Attendance Compliance Tracker**
    
    Args:
        query: User query about training, competency, certifications, etc.
        
    Returns:
        Formatted string with training documents from APQR_Segregated/DMS/
    """
    logger.info(f"ğŸ‘¨â€ğŸ“ DMS Training Tool called with query: {query}")
    
    # ğŸ” NEW: Read the DMS database index for intelligent file search
    dms_index = read_database_index("DMS")
    if dms_index:
        logger.info("âœ… DMS database index loaded for intelligent file search")
    
    # List available DMS documents
    available_docs = list_available_documents(DMS_DOCS_DIR)
    
    result = f"""**ğŸ‘¨â€ğŸ“ HR & Training Records (DMS)**

**Query:** {query}

**Available Training Documents:** {len(available_docs)} files

**Data Source:** DMS APQR_Segregated/DMS/

**HR & Training Capabilities:**
- âœ… Training Matrix Reader: Read and analyze training matrices
- âœ… Competency Evaluation Extractor: Extract competency assessment data
- âœ… Attendance Compliance Tracker: Track training attendance and compliance
- âœ… Certification management

**Available Data Types:**
- Training matrices and curriculum
- Competency assessments
- Certification records and tracking
- Training compliance monitoring
- GMP training status
- Attendance records
- Qualification documentation

**Documents:** {', '.join(available_docs)}

**Training Focus:**
- Competency verification
- Training compliance
- Certification tracking
- GMP training
- Curriculum management
- Skills assessment
"""
    
    return result

